{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# **CS224W - Colab 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "print(torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gzsP50bF6Gb"
   },
   "source": [
    "In this Colab, we will construct our own graph neural network by using PyTorch Geometric (PyG) and apply the model on two of Open Graph Benchmark (OGB) datasets. Those two datasets are used to benchmark the model performance on two different graph-related tasks. One is node property prediction, predicting properties of single nodes. Another one is graph property prediction, predicting the entire graphs or subgraphs.\n",
    "\n",
    "At first, we will learn how PyTorch Geometric stores the graphs in PyTorch tensor.\n",
    "\n",
    "We will then load and take a quick look on one of the Open Graph Benchmark (OGB) datasets by using the `ogb` package. OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. The `ogb` package not only provides the data loader of the dataset but also the evaluator.\n",
    "\n",
    "At last, we will build our own graph neural networks by using PyTorch Geometric. And then apply and evaluate the models on node property prediction and grpah property prediction tasks.\n",
    "\n",
    "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n",
    "\n",
    "Have fun on Colab 2 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGKqVEbbMEzf"
   },
   "source": [
    "# Device\n",
    "You might need to use GPU for this Colab.\n",
    "\n",
    "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0NiFL6OLpaJ"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "By2oyBw7Lrh5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ogb in /storage/zjwu/anaconda3/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (0.24.1)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (4.59.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (1.16.0)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (1.10.1)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from ogb) (1.2.4)\n",
      "Requirement already satisfied: littleutils in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
      "Requirement already satisfied: requests in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.6.2)\n",
      "Requirement already satisfied: typing-extensions in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /storage/zjwu/anaconda3/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "#pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "#pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "#pip install -q torch-geometric\n",
    "!pip install ogb\n",
    "# already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwwq0nSdmsOL"
   },
   "source": [
    "# 1 PyTorch Geometric (Datasets and Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf7vUmdNKCjA"
   },
   "source": [
    "PyTorch Geometric generally has two classes for storing or transforming the graphs into tensor format. One is the `torch_geometric.datasets`, which contains a variety of common graph datasets. Another one is `torch_geometric.data` that provides the data handling of graphs in PyTorch tensors.\n",
    "\n",
    "In this section, we will learn how to use the `torch_geometric.datasets` and `torch_geometric.data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-o1P3r6hr2"
   },
   "source": [
    "## PyG Datasets\n",
    "\n",
    "The `torch_geometric.datasets` has many common graph datasets. Here we will explore the usage by using one example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zT5qca3x6XpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(600)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "root = './enzymes'\n",
    "name = 'ENZYMES'\n",
    "\n",
    "# The ENZYMES dataset\n",
    "pyg_dataset= TUDataset('./enzymes', 'ENZYMES')\n",
    "\n",
    "# You can find that there are 600 graphs in this dataset\n",
    "print(pyg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLm5vVYMAP2x"
   },
   "source": [
    "## Question 1: What is the number of classes and number of features in the ENZYMES dataset? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TUDataset in module torch_geometric.datasets.tu_dataset object:\n",
      "\n",
      "class TUDataset(torch_geometric.data.in_memory_dataset.InMemoryDataset)\n",
      " |  TUDataset(*args, **kwds)\n",
      " |  \n",
      " |  A variety of graph kernel benchmark datasets, *.e.g.* \"IMDB-BINARY\",\n",
      " |  \"REDDIT-BINARY\" or \"PROTEINS\", collected from the `TU Dortmund University\n",
      " |  <https://chrsmrrs.github.io/datasets>`_.\n",
      " |  In addition, this dataset wrapper provides `cleaned dataset versions\n",
      " |  <https://github.com/nd7141/graph_datasets>`_ as motivated by the\n",
      " |  `\"Understanding Isomorphism Bias in Graph Data Sets\"\n",
      " |  <https://arxiv.org/abs/1910.12091>`_ paper, containing only non-isomorphic\n",
      " |  graphs.\n",
      " |  \n",
      " |  .. note::\n",
      " |      Some datasets may not come with any node labels.\n",
      " |      You can then either make use of the argument :obj:`use_node_attr`\n",
      " |      to load additional continuous node attributes (if present) or provide\n",
      " |      synthetic node features using transforms such as\n",
      " |      like :class:`torch_geometric.transforms.Constant` or\n",
      " |      :class:`torch_geometric.transforms.OneHotDegree`.\n",
      " |  \n",
      " |  Args:\n",
      " |      root (string): Root directory where the dataset should be saved.\n",
      " |      name (string): The `name\n",
      " |          <https://chrsmrrs.github.io/datasets/docs/datasets/>`_ of the\n",
      " |          dataset.\n",
      " |      transform (callable, optional): A function/transform that takes in an\n",
      " |          :obj:`torch_geometric.data.Data` object and returns a transformed\n",
      " |          version. The data object will be transformed before every access.\n",
      " |          (default: :obj:`None`)\n",
      " |      pre_transform (callable, optional): A function/transform that takes in\n",
      " |          an :obj:`torch_geometric.data.Data` object and returns a\n",
      " |          transformed version. The data object will be transformed before\n",
      " |          being saved to disk. (default: :obj:`None`)\n",
      " |      pre_filter (callable, optional): A function that takes in an\n",
      " |          :obj:`torch_geometric.data.Data` object and returns a boolean\n",
      " |          value, indicating whether the data object should be included in the\n",
      " |          final dataset. (default: :obj:`None`)\n",
      " |      use_node_attr (bool, optional): If :obj:`True`, the dataset will\n",
      " |          contain additional continuous node attributes (if present).\n",
      " |          (default: :obj:`False`)\n",
      " |      use_edge_attr (bool, optional): If :obj:`True`, the dataset will\n",
      " |          contain additional continuous edge attributes (if present).\n",
      " |          (default: :obj:`False`)\n",
      " |      cleaned: (bool, optional): If :obj:`True`, the dataset will\n",
      " |          contain only non-isomorphic graphs. (default: :obj:`False`)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TUDataset\n",
      " |      torch_geometric.data.in_memory_dataset.InMemoryDataset\n",
      " |      torch_geometric.data.dataset.Dataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root: str, name: str, transform: Union[Callable, NoneType] = None, pre_transform: Union[Callable, NoneType] = None, pre_filter: Union[Callable, NoneType] = None, use_node_attr: bool = False, use_edge_attr: bool = False, cleaned: bool = False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  download(self)\n",
      " |      Downloads the dataset to the :obj:`self.raw_dir` folder.\n",
      " |  \n",
      " |  process(self)\n",
      " |      Processes the dataset to the :obj:`self.processed_dir` folder.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  num_edge_attributes\n",
      " |  \n",
      " |  num_edge_labels\n",
      " |  \n",
      " |  num_node_attributes\n",
      " |  \n",
      " |  num_node_labels\n",
      " |  \n",
      " |  processed_dir\n",
      " |  \n",
      " |  processed_file_names\n",
      " |      The name of the files in the :obj:`self.processed_dir` folder that\n",
      " |      must be present in order to skip processing.\n",
      " |  \n",
      " |  raw_dir\n",
      " |  \n",
      " |  raw_file_names\n",
      " |      The name of the files in the :obj:`self.raw_dir` folder that must\n",
      " |      be present in order to skip downloading.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  cleaned_url = 'https://raw.githubusercontent.com/nd7141/graph_datasets...\n",
      " |  \n",
      " |  url = 'https://www.chrsmrrs.com/graphkerneldatasets'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch_geometric.data.in_memory_dataset.InMemoryDataset:\n",
      " |  \n",
      " |  copy(self, idx: Union[slice, torch.Tensor, numpy.ndarray, collections.abc.Sequence, NoneType] = None) -> 'InMemoryDataset'\n",
      " |      Performs a deep-copy of the dataset. If :obj:`idx` is not given,\n",
      " |      will clone the full dataset. Otherwise, will only clone a subset of the\n",
      " |      dataset from indices :obj:`idx`.\n",
      " |      Indices can be slices, lists, tuples, and a :obj:`torch.Tensor` or\n",
      " |      :obj:`np.ndarray` of type long or bool.\n",
      " |  \n",
      " |  get(self, idx: int) -> torch_geometric.data.data.Data\n",
      " |      Gets the data object at index :obj:`idx`.\n",
      " |  \n",
      " |  len(self) -> int\n",
      " |      Returns the number of graphs stored in the dataset.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from torch_geometric.data.in_memory_dataset.InMemoryDataset:\n",
      " |  \n",
      " |  collate(data_list: List[torch_geometric.data.data.Data]) -> Tuple[torch_geometric.data.data.Data, Union[Dict[str, torch.Tensor], NoneType]]\n",
      " |      Collates a Python list of :obj:`torch_geometric.data.Data` objects\n",
      " |      to the internal storage format of\n",
      " |      :class:`~torch_geometric.data.InMemoryDataset`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch_geometric.data.in_memory_dataset.InMemoryDataset:\n",
      " |  \n",
      " |  num_classes\n",
      " |      Returns the number of classes in the dataset.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch_geometric.data.dataset.Dataset:\n",
      " |  \n",
      " |  __getitem__(self, idx: Union[int, numpy.integer, slice, torch.Tensor, numpy.ndarray, collections.abc.Sequence]) -> Union[ForwardRef('Dataset'), torch_geometric.data.data.Data]\n",
      " |      In case :obj:`idx` is of type integer, will return the data object\n",
      " |      at index :obj:`idx` (and transforms it in case :obj:`transform` is\n",
      " |      present).\n",
      " |      In case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\n",
      " |      tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\n",
      " |      bool, will return a subset of the dataset at the specified indices.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |      The number of examples in the dataset.\n",
      " |  \n",
      " |  index_select(self, idx: Union[slice, torch.Tensor, numpy.ndarray, collections.abc.Sequence]) -> 'Dataset'\n",
      " |      Creates a subset of the dataset from specified indices :obj:`idx`.\n",
      " |      Indices :obj:`idx` can be a slicing object, *e.g.*, :obj:`[2:5]`, a\n",
      " |      list, a tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type\n",
      " |      long or bool.\n",
      " |  \n",
      " |  indices(self) -> collections.abc.Sequence\n",
      " |  \n",
      " |  shuffle(self, return_perm: bool = False) -> Union[ForwardRef('Dataset'), Tuple[ForwardRef('Dataset'), torch.Tensor]]\n",
      " |      Randomly shuffles the examples in the dataset.\n",
      " |      \n",
      " |      Args:\n",
      " |          return_perm (bool, optional): If set to :obj:`True`, will also\n",
      " |              return the random permutation used to shuffle the dataset.\n",
      " |              (default: :obj:`False`)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch_geometric.data.dataset.Dataset:\n",
      " |  \n",
      " |  num_edge_features\n",
      " |      Returns the number of features per edge in the dataset.\n",
      " |  \n",
      " |  num_features\n",
      " |      Returns the number of features per node in the dataset.\n",
      " |      Alias for :py:attr:`~num_node_features`.\n",
      " |  \n",
      " |  num_node_features\n",
      " |      Returns the number of features per node in the dataset.\n",
      " |  \n",
      " |  processed_paths\n",
      " |      The absolute filepaths that must be present in order to skip\n",
      " |      processing.\n",
      " |  \n",
      " |  raw_paths\n",
      " |      The absolute filepaths that must be present in order to skip\n",
      " |      downloading.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getattr__(self, attribute_name)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  register_datapipe_as_function(function_name, cls_to_register, enable_df_api_tracing=False) from builtins.type\n",
      " |  \n",
      " |  register_function(function_name, function) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __annotations__ = {'functions': typing.Dict[str, typing.Callable]}\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  functions = {'concat': functools.partial(<function Dataset.register_da...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pyg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8iF_Kyqr_JbY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES dataset has 6 classes\n",
      "ENZYMES dataset has 3 features\n"
     ]
    }
   ],
   "source": [
    "def get_num_classes(pyg_dataset):\n",
    "  # TODO: Implement this function that takes a PyG dataset object\n",
    "  # and return the number of classes for that dataset.\n",
    "\n",
    "    num_classes = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note\n",
    "    ## 1. Colab autocomplete functionality might be useful.\n",
    "    num_classes = pyg_dataset.num_classes\n",
    "    #########################################\n",
    "\n",
    "    return num_classes\n",
    "\n",
    "def get_num_features(pyg_dataset):\n",
    "  # TODO: Implement this function that takes a PyG dataset object\n",
    "  # and return the number of features for that dataset.\n",
    "\n",
    "    num_features = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note\n",
    "    ## 1. Colab autocomplete functionality might be useful.\n",
    "    num_features = pyg_dataset.num_node_features\n",
    "    #########################################\n",
    "\n",
    "    return num_features\n",
    "\n",
    "# You may find that some information need to be stored in the dataset level,\n",
    "# specifically if there are multiple graphs in the dataset\n",
    "\n",
    "num_classes = get_num_classes(pyg_dataset)\n",
    "num_features = get_num_features(pyg_dataset)\n",
    "print(\"{} dataset has {} classes\".format(name, num_classes))\n",
    "print(\"{} dataset has {} features\".format(name, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwKbzhHUAckZ"
   },
   "source": [
    "## PyG Data\n",
    "\n",
    "Each PyG dataset usually stores a list of `torch_geometric.data.Data` objects. Each `torch_geometric.data.Data` object usually represents a graph. You can easily get the `Data` object by indexing on the dataset.\n",
    "\n",
    "For more information such as what will be stored in `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sCV3xJWCddX"
   },
   "source": [
    "## Question 2: What is the label of the graph (index 100 in the ENZYMES dataset)? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LIis9oTZAfs3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "Graph with index 100 has label 4\n"
     ]
    }
   ],
   "source": [
    "def get_graph_class(pyg_dataset, idx):\n",
    "    # TODO: Implement this function that takes a PyG dataset object,\n",
    "    # the index of the graph in dataset, and returns the class/label \n",
    "    # of the graph (in integer).\n",
    "\n",
    "    label = -1\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    #########################################\n",
    "    label = pyg_dataset[idx].y.item()\n",
    "    return label\n",
    "\n",
    "# Here pyg_dataset is a dataset for graph classification\n",
    "graph_0 = pyg_dataset[0]\n",
    "print(graph_0)\n",
    "idx = 100\n",
    "label = get_graph_class(pyg_dataset, idx)\n",
    "print('Graph with index {} has label {}'.format(idx, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKhcVeAhCwoY"
   },
   "source": [
    "## Question 3: What is the number of edges for the graph (index 200 in the ENZYMES dataset)? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_dataset[100].edge_index.size()[1]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_dataset[100].num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f5m2DOfhBtWv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with index 200 has 53 edges\n"
     ]
    }
   ],
   "source": [
    "def get_graph_num_edges(pyg_dataset, idx):\n",
    "    # TODO: Implement this function that takes a PyG dataset object,\n",
    "    # the index of the graph in dataset, and returns the number of \n",
    "    # edges in the graph (in integer). You should not count an edge \n",
    "    # twice if the graph is undirected. For example, in an undirected \n",
    "    # graph G, if two nodes v and u are connected by an edge, this edge\n",
    "    # should only be counted once.\n",
    "\n",
    "    num_edges = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. You can't return the data.num_edges directly\n",
    "    ## 2. We assume the graph is undirected\n",
    "    ## (~4 lines of code)\n",
    "    num_edges = int(pyg_dataset[idx].edge_index.size()[1] / 2)\n",
    "    #########################################\n",
    "\n",
    "    return num_edges\n",
    "\n",
    "idx = 200\n",
    "num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
    "print('Graph with index {} has {} edges'.format(idx, num_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXa7yIG4E0Fp"
   },
   "source": [
    "# 2 Open Graph Benchmark (OGB)\n",
    "\n",
    "The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can also be evaluated by using the OGB Evaluator in a unified manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnazPGGAJAZN"
   },
   "source": [
    "## Dataset and Data\n",
    "\n",
    "OGB also supports the PyG dataset and data. Here we take a look on the `ogbn-arxiv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "import ogb\n",
    "print(ogb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Gpc6bTm3GF02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ogbn-arxiv dataset has 1 graph\n",
      "Data(x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=1166243])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset_name = 'ogbn-arxiv'\n",
    "# Load the dataset and transform it to sparse tensor\n",
    "dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                 transform=T.ToSparseTensor())\n",
    "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
    "\n",
    "# Extract the graph\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1166243"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cw0xZJKZI-n3"
   },
   "source": [
    "## Question 4: What is the number of features in the ogbn-arxiv graph? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZP844_nT2ZJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph has 128 features\n"
     ]
    }
   ],
   "source": [
    "def graph_num_features(data):\n",
    "    # TODO: Implement this function that takes a PyG data object,\n",
    "    # and returns the number of features in the graph (in integer).\n",
    "\n",
    "    num_features = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    num_features = data.num_features\n",
    "    #########################################\n",
    "\n",
    "    return num_features\n",
    "\n",
    "num_features = graph_num_features(data)\n",
    "print('The graph has {} features'.format(num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DP_yEQZ0NVW"
   },
   "source": [
    "# 3 GNN: Node Property Prediction\n",
    "\n",
    "In this section we will build our first graph neural network by using PyTorch Geometric and apply it on node property prediction (node classification).\n",
    "\n",
    "We will build the graph neural network by using GCN operator ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)).\n",
    "\n",
    "You should use the PyG built-in `GCNConv` layer directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4CcOUEoInjD"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-DCtgcHpGIpd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IK9z0wQIwzQ"
   },
   "source": [
    "## Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0ibJ0ieoIwQM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ogbn-arxiv'\n",
    "dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                 transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "\n",
    "# Make the adjacency matrix to symmetric\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "data = data.to(device)\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]),\n",
       " 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]),\n",
       " 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgUA815bNJ8w"
   },
   "source": [
    "## GCN Model\n",
    "\n",
    "Now we will implement our GCN model!\n",
    "\n",
    "Please follow the figure below to implement your `forward` function.\n",
    "\n",
    "\n",
    "![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModuleList文档示例\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linears = torch.nn.ModuleList([torch.nn.Linear(10, 10) for i in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.linears[i // 2](x) + l(x)  #//是整数除法\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModule(\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (4): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (5): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (6): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (7): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (8): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (9): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_sample = MyModule()\n",
    "module_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "IgspXTYpNJLA"
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        # TODO: Implement this function that initializes self.convs, \n",
    "        # self.bns, and self.softmax.\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = None\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = None\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
    "        ## 2. self.convs has num_layers GCNConv layers\n",
    "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
    "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
    "        ## 5. The parameters you can set for GCNConv include 'in_channels' and \n",
    "        ## 'out_channels'. More information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
    "        ## More information please refer to the documentation: \n",
    "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        ## (~10 lines of code)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(num_layers-1):\n",
    "            self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "            input_dim = hidden_dim\n",
    "        self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "        \n",
    "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(hidden_dim) for i in range(num_layers - 1)])\n",
    "        \n",
    "        self.softmax = torch.nn.LogSoftmax()\n",
    "        #########################################\n",
    "\n",
    "        # Probability of an element to be zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        # TODO: Implement this function that takes the feature tensor x,\n",
    "        # edge_index tensor adj_t and returns the output tensor as\n",
    "        # shown in the figure.\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct the network as showing in the figure\n",
    "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## More information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. Don't forget to set F.dropout training to self.training\n",
    "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
    "        ## (~7 lines of code)\n",
    "        for layer in range(len(self.convs) - 1):\n",
    "            x = self.convs[layer](x, adj_t)\n",
    "            x = self.bns[layer](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, self.training)\n",
    "        out = self.convs[-1](x, adj_t)\n",
    "        \n",
    "        if not self.return_embeds:\n",
    "            return self.softmax(out)\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  5, 28,  ..., 28, 23, 22], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[train_idx].squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FF1hnHUhO81e"
   },
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, loss_fn):\n",
    "    # TODO: Implement this function that trains the model by \n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    ## 2. Feed the data into the model\n",
    "    ## 3. Slicing the model output and label by train_idx\n",
    "    ## 4. Feed the sliced output and label to loss_fn\n",
    "    ## (~4 lines of code)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)\n",
    "    train_output = out[train_idx]\n",
    "    train_label = data.y[train_idx].squeeze(1)\n",
    "    loss = loss_fn(train_output, train_label)\n",
    "    #########################################\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "aJdlrJQhPBsK"
   },
   "outputs": [],
   "source": [
    "# Test function here\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    # TODO: Implement this function that tests the model by \n",
    "    # using the given split_idx and evaluator.\n",
    "    model.eval()\n",
    "\n",
    "    # The output of model on all data\n",
    "    out = None\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note:\n",
    "    ## 1. No index slicing here\n",
    "    out = model(data.x, data.adj_t)\n",
    "    #########################################\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "o7F46xkuLiOL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cuda',\n",
       " 'num_layers': 3,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 100}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please do not change the args\n",
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 3,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.01,\n",
    "    'epochs': 100,\n",
    "}\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dT8RyM2cPGxM"
   },
   "outputs": [],
   "source": [
    "model = GCN(data.num_features, args['hidden_dim'],\n",
    "            dataset.num_classes, args['num_layers'],\n",
    "            args['dropout']).to(device)\n",
    "evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qd5O5cnPPdVF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/zjwu/.local/lib/python3.7/site-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 4.1180, Train: 26.41%, Valid: 29.63% Test: 26.55%\n",
      "Epoch: 02, Loss: 2.3760, Train: 21.42%, Valid: 17.08% Test: 20.02%\n",
      "Epoch: 03, Loss: 1.9981, Train: 20.52%, Valid: 11.06% Test: 9.96%\n",
      "Epoch: 04, Loss: 1.8219, Train: 24.77%, Valid: 13.92% Test: 11.94%\n",
      "Epoch: 05, Loss: 1.7067, Train: 30.75%, Valid: 17.50% Test: 14.17%\n",
      "Epoch: 06, Loss: 1.6141, Train: 35.35%, Valid: 21.61% Test: 18.11%\n",
      "Epoch: 07, Loss: 1.5322, Train: 38.76%, Valid: 28.88% Test: 27.93%\n",
      "Epoch: 08, Loss: 1.4702, Train: 39.79%, Valid: 33.88% Test: 35.48%\n",
      "Epoch: 09, Loss: 1.4137, Train: 39.85%, Valid: 33.27% Test: 33.95%\n",
      "Epoch: 10, Loss: 1.3728, Train: 40.07%, Valid: 30.86% Test: 30.35%\n",
      "Epoch: 11, Loss: 1.3455, Train: 41.36%, Valid: 31.28% Test: 30.75%\n",
      "Epoch: 12, Loss: 1.3187, Train: 43.94%, Valid: 37.04% Test: 39.53%\n",
      "Epoch: 13, Loss: 1.2917, Train: 46.49%, Valid: 42.63% Test: 46.48%\n",
      "Epoch: 14, Loss: 1.2679, Train: 49.54%, Valid: 48.23% Test: 51.56%\n",
      "Epoch: 15, Loss: 1.2516, Train: 53.16%, Valid: 53.08% Test: 55.00%\n",
      "Epoch: 16, Loss: 1.2334, Train: 56.34%, Valid: 56.60% Test: 57.33%\n",
      "Epoch: 17, Loss: 1.2180, Train: 58.43%, Valid: 59.13% Test: 59.36%\n",
      "Epoch: 18, Loss: 1.2070, Train: 59.46%, Valid: 60.43% Test: 61.05%\n",
      "Epoch: 19, Loss: 1.1944, Train: 59.70%, Valid: 60.98% Test: 62.49%\n",
      "Epoch: 20, Loss: 1.1748, Train: 59.97%, Valid: 61.52% Test: 63.29%\n",
      "Epoch: 21, Loss: 1.1712, Train: 60.07%, Valid: 61.59% Test: 63.75%\n",
      "Epoch: 22, Loss: 1.1587, Train: 59.97%, Valid: 61.27% Test: 63.89%\n",
      "Epoch: 23, Loss: 1.1480, Train: 59.83%, Valid: 60.88% Test: 63.89%\n",
      "Epoch: 24, Loss: 1.1439, Train: 60.35%, Valid: 61.07% Test: 64.12%\n",
      "Epoch: 25, Loss: 1.1362, Train: 61.54%, Valid: 62.13% Test: 64.93%\n",
      "Epoch: 26, Loss: 1.1269, Train: 62.81%, Valid: 63.42% Test: 65.58%\n",
      "Epoch: 27, Loss: 1.1161, Train: 63.87%, Valid: 64.39% Test: 66.14%\n",
      "Epoch: 28, Loss: 1.1061, Train: 64.71%, Valid: 65.21% Test: 66.48%\n",
      "Epoch: 29, Loss: 1.1001, Train: 65.31%, Valid: 65.82% Test: 66.80%\n",
      "Epoch: 30, Loss: 1.0951, Train: 65.92%, Valid: 66.25% Test: 67.13%\n",
      "Epoch: 31, Loss: 1.0869, Train: 66.37%, Valid: 66.40% Test: 67.37%\n",
      "Epoch: 32, Loss: 1.0855, Train: 66.75%, Valid: 66.81% Test: 67.57%\n",
      "Epoch: 33, Loss: 1.0795, Train: 67.23%, Valid: 67.17% Test: 67.85%\n",
      "Epoch: 34, Loss: 1.0744, Train: 67.56%, Valid: 67.43% Test: 67.94%\n",
      "Epoch: 35, Loss: 1.0690, Train: 67.60%, Valid: 67.28% Test: 67.99%\n",
      "Epoch: 36, Loss: 1.0645, Train: 67.86%, Valid: 67.41% Test: 68.11%\n",
      "Epoch: 37, Loss: 1.0588, Train: 68.33%, Valid: 67.90% Test: 68.51%\n",
      "Epoch: 38, Loss: 1.0568, Train: 68.90%, Valid: 68.66% Test: 68.98%\n",
      "Epoch: 39, Loss: 1.0500, Train: 69.35%, Valid: 69.30% Test: 69.32%\n",
      "Epoch: 40, Loss: 1.0462, Train: 69.68%, Valid: 69.46% Test: 69.54%\n",
      "Epoch: 41, Loss: 1.0398, Train: 69.82%, Valid: 69.50% Test: 69.72%\n",
      "Epoch: 42, Loss: 1.0438, Train: 69.94%, Valid: 69.53% Test: 69.83%\n",
      "Epoch: 43, Loss: 1.0342, Train: 70.10%, Valid: 69.73% Test: 69.77%\n",
      "Epoch: 44, Loss: 1.0297, Train: 70.35%, Valid: 69.85% Test: 69.07%\n",
      "Epoch: 45, Loss: 1.0264, Train: 70.38%, Valid: 69.71% Test: 68.40%\n",
      "Epoch: 46, Loss: 1.0213, Train: 70.52%, Valid: 70.00% Test: 69.11%\n",
      "Epoch: 47, Loss: 1.0226, Train: 70.62%, Valid: 69.97% Test: 69.07%\n",
      "Epoch: 48, Loss: 1.0197, Train: 70.78%, Valid: 69.84% Test: 68.43%\n",
      "Epoch: 49, Loss: 1.0133, Train: 70.83%, Valid: 69.60% Test: 67.93%\n",
      "Epoch: 50, Loss: 1.0114, Train: 70.93%, Valid: 69.61% Test: 67.99%\n",
      "Epoch: 51, Loss: 1.0101, Train: 71.07%, Valid: 70.20% Test: 69.13%\n",
      "Epoch: 52, Loss: 1.0071, Train: 71.10%, Valid: 70.33% Test: 69.81%\n",
      "Epoch: 53, Loss: 1.0034, Train: 71.01%, Valid: 70.17% Test: 69.76%\n",
      "Epoch: 54, Loss: 1.0001, Train: 71.15%, Valid: 70.30% Test: 69.43%\n",
      "Epoch: 55, Loss: 0.9991, Train: 71.31%, Valid: 70.26% Test: 68.82%\n",
      "Epoch: 56, Loss: 0.9963, Train: 71.43%, Valid: 70.18% Test: 68.39%\n",
      "Epoch: 57, Loss: 0.9953, Train: 71.54%, Valid: 70.29% Test: 68.71%\n",
      "Epoch: 58, Loss: 0.9906, Train: 71.69%, Valid: 70.42% Test: 69.13%\n",
      "Epoch: 59, Loss: 0.9889, Train: 71.71%, Valid: 70.46% Test: 69.24%\n",
      "Epoch: 60, Loss: 0.9879, Train: 71.82%, Valid: 70.67% Test: 69.53%\n",
      "Epoch: 61, Loss: 0.9856, Train: 71.82%, Valid: 70.72% Test: 69.92%\n",
      "Epoch: 62, Loss: 0.9812, Train: 71.73%, Valid: 70.79% Test: 70.17%\n",
      "Epoch: 63, Loss: 0.9796, Train: 71.86%, Valid: 70.80% Test: 70.05%\n",
      "Epoch: 64, Loss: 0.9797, Train: 72.01%, Valid: 70.46% Test: 69.24%\n",
      "Epoch: 65, Loss: 0.9749, Train: 71.92%, Valid: 69.86% Test: 68.05%\n",
      "Epoch: 66, Loss: 0.9736, Train: 72.02%, Valid: 70.23% Test: 68.48%\n",
      "Epoch: 67, Loss: 0.9699, Train: 72.22%, Valid: 71.08% Test: 70.28%\n",
      "Epoch: 68, Loss: 0.9682, Train: 72.09%, Valid: 71.10% Test: 70.73%\n",
      "Epoch: 69, Loss: 0.9667, Train: 72.20%, Valid: 71.15% Test: 70.71%\n",
      "Epoch: 70, Loss: 0.9653, Train: 72.48%, Valid: 71.17% Test: 70.10%\n",
      "Epoch: 71, Loss: 0.9654, Train: 72.51%, Valid: 70.91% Test: 69.34%\n",
      "Epoch: 72, Loss: 0.9614, Train: 72.62%, Valid: 71.04% Test: 69.64%\n",
      "Epoch: 73, Loss: 0.9586, Train: 72.60%, Valid: 71.52% Test: 70.42%\n",
      "Epoch: 74, Loss: 0.9562, Train: 72.66%, Valid: 71.51% Test: 70.64%\n",
      "Epoch: 75, Loss: 0.9522, Train: 72.75%, Valid: 71.48% Test: 70.56%\n",
      "Epoch: 76, Loss: 0.9546, Train: 72.76%, Valid: 71.52% Test: 70.54%\n",
      "Epoch: 77, Loss: 0.9536, Train: 72.84%, Valid: 71.45% Test: 70.25%\n",
      "Epoch: 78, Loss: 0.9489, Train: 72.84%, Valid: 71.14% Test: 69.62%\n",
      "Epoch: 79, Loss: 0.9467, Train: 72.92%, Valid: 70.89% Test: 69.32%\n",
      "Epoch: 80, Loss: 0.9468, Train: 72.99%, Valid: 71.32% Test: 70.25%\n",
      "Epoch: 81, Loss: 0.9453, Train: 72.89%, Valid: 71.44% Test: 70.74%\n",
      "Epoch: 82, Loss: 0.9446, Train: 72.75%, Valid: 71.34% Test: 70.60%\n",
      "Epoch: 83, Loss: 0.9430, Train: 72.81%, Valid: 71.33% Test: 70.28%\n",
      "Epoch: 84, Loss: 0.9390, Train: 73.01%, Valid: 71.51% Test: 70.40%\n",
      "Epoch: 85, Loss: 0.9403, Train: 73.21%, Valid: 71.72% Test: 70.80%\n",
      "Epoch: 86, Loss: 0.9358, Train: 73.25%, Valid: 71.91% Test: 71.18%\n",
      "Epoch: 87, Loss: 0.9353, Train: 73.24%, Valid: 71.84% Test: 70.87%\n",
      "Epoch: 88, Loss: 0.9331, Train: 73.25%, Valid: 71.30% Test: 69.77%\n",
      "Epoch: 89, Loss: 0.9313, Train: 73.34%, Valid: 71.45% Test: 70.21%\n",
      "Epoch: 90, Loss: 0.9281, Train: 73.41%, Valid: 71.72% Test: 71.02%\n",
      "Epoch: 91, Loss: 0.9287, Train: 73.46%, Valid: 71.71% Test: 70.70%\n",
      "Epoch: 92, Loss: 0.9267, Train: 73.36%, Valid: 71.10% Test: 69.47%\n",
      "Epoch: 93, Loss: 0.9276, Train: 73.39%, Valid: 71.50% Test: 70.37%\n",
      "Epoch: 94, Loss: 0.9225, Train: 73.29%, Valid: 71.84% Test: 71.59%\n",
      "Epoch: 95, Loss: 0.9208, Train: 73.49%, Valid: 71.73% Test: 71.09%\n",
      "Epoch: 96, Loss: 0.9202, Train: 73.51%, Valid: 70.94% Test: 69.09%\n",
      "Epoch: 97, Loss: 0.9224, Train: 73.39%, Valid: 70.86% Test: 69.09%\n",
      "Epoch: 98, Loss: 0.9159, Train: 73.49%, Valid: 71.22% Test: 69.80%\n",
      "Epoch: 99, Loss: 0.9147, Train: 73.64%, Valid: 71.28% Test: 69.70%\n",
      "Epoch: 100, Loss: 0.9125, Train: 73.81%, Valid: 71.80% Test: 70.53%\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# reset the parameters to initial random value\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "loss_fn = F.nll_loss\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * valid_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "EqcextqOL2FX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Train: 73.25%, Valid: 71.91% Test: 71.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/zjwu/.local/lib/python3.7/site-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "best_result = test(best_model, data, split_idx, evaluator)\n",
    "train_acc, valid_acc, test_acc = best_result\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * train_acc:.2f}%, '\n",
    "      f'Valid: {100 * valid_acc:.2f}% '\n",
    "      f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duMEg-olLjbJ"
   },
   "source": [
    "## Question 5: What are your `best_model` validation and test accuracy? Please report them on Gradescope. For example, for an accuracy such as 50.01%, just report 50.01 and please don't include the percent sign. (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8pOD6y80TyI"
   },
   "source": [
    "# 4 GNN: Graph Property Prediction\n",
    "\n",
    "In this section we will create a graph neural network for graph property prediction (graph classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRg5VOEdQTa4"
   },
   "source": [
    "## Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "LXb-O5QUIgTH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/hiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 41127/41127 [00:00<00:00, 87924.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 41127/41127 [00:01<00:00, 38708.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Device: cuda\n",
      "Task type: binary classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load the dataset \n",
    "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "\n",
    "# Check task type\n",
    "print('Task type: {}'.format(dataset.task_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "7cHHbgW1c5hi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/zjwu/anaconda3/envs/torch/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Load the data sets into dataloader\n",
    "# We will train the graph classification task on a batch of 32 graphs\n",
    "# Shuffle the order of graphs for training set\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "AYrSnOj0Y4DK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cuda',\n",
       " 'num_layers': 5,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 30}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please do not change the args\n",
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 5,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 30,\n",
    "}\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WLhguSTeazy"
   },
   "source": [
    "## Graph Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u05Z14TRYPGn"
   },
   "source": [
    "Now we will implement our GCN Graph Prediction model!\n",
    "\n",
    "We will reuse the existing GCN model to generate `node_embeddings` and use  Global Pooling on the nodes to predict properties for the whole graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "3_Kq3zyjeZ22"
   },
   "outputs": [],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool\n",
    "\n",
    "### GCN to predict graph property\n",
    "class GCN_Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GCN_Graph, self).__init__()\n",
    "\n",
    "        # Load encoders for Atoms in molecule graphs\n",
    "        self.node_encoder = AtomEncoder(hidden_dim)\n",
    "\n",
    "        # Node embedding model\n",
    "        # Note that the input_dim and output_dim are set to hidden_dim\n",
    "        self.gnn_node = GCN(hidden_dim, hidden_dim,\n",
    "            hidden_dim, num_layers, dropout, return_embeds=True)\n",
    "\n",
    "        self.pool = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Initialize the self.pool to global mean pooling layer\n",
    "        ## More information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "        ## (~1 line of code)\n",
    "        self.pool = global_mean_pool\n",
    "        #########################################\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gnn_node.reset_parameters()\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        # TODO: Implement this function that takes the input tensor batched_data,\n",
    "        # returns a batched output tensor for each graph.\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        embed = self.node_encoder(x)\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct node embeddings using existing GCN model\n",
    "        ## 2. Use global pooling layer to construct features for the whole graph\n",
    "        ## More information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "        ## 3. Use a linear layer to predict the graph property \n",
    "        ## (~3 lines of code)\n",
    "        out = self.gnn_node(embed, edge_index)\n",
    "        out = self.pool(out, batch)\n",
    "        out = self.linear(out)\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "FJjnGuMSbjX0"
   },
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, loss_fn):\n",
    "    # TODO: Implement this function that trains the model by \n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "        ## ignore nan targets (unlabeled) when computing training loss.\n",
    "            is_labeled = batch.y == batch.y\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Feed the data into the model\n",
    "        ## 3. Use `is_labeled` mask to filter output and labels\n",
    "        ## 4. You might change the type of label\n",
    "        ## 5. Feed the output and label to loss_fn\n",
    "        ## (~3 lines of code)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = loss_fn(out[is_labeled], batch.y[is_labeled].type_as(out))\n",
    "        #########################################\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ztPHXq_Gzn7U"
   },
   "outputs": [],
   "source": [
    "# The evaluation function\n",
    "def eval(model, device, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "MR1wQ4hMZeMw"
   },
   "outputs": [],
   "source": [
    "model = GCN_Graph(args['hidden_dim'],\n",
    "            dataset.num_tasks, args['num_layers'],\n",
    "            args['dropout']).to(device)\n",
    "evaluator = Evaluator(name='ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "qJGTNZiuZy0A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:30<00:00, 33.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.53it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 46.18it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 50.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.0656, Train: 73.12%, Valid: 67.01% Test: 65.68%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:26<00:00, 38.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.58it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.95it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 55.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Loss: 0.0245, Train: 72.27%, Valid: 66.93% Test: 69.20%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 38.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.72it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.32it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 52.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Loss: 0.0498, Train: 74.06%, Valid: 74.77% Test: 72.97%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.27it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.59it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Loss: 0.0776, Train: 76.43%, Valid: 77.51% Test: 72.01%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:28<00:00, 36.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 55.44it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.77it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Loss: 0.0311, Train: 77.66%, Valid: 74.45% Test: 71.39%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.74it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.75it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Loss: 0.0288, Train: 76.69%, Valid: 74.31% Test: 69.26%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.62it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 59.00it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Loss: 0.0331, Train: 79.10%, Valid: 77.65% Test: 71.85%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.47it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.32it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Loss: 0.0191, Train: 78.78%, Valid: 77.17% Test: 70.56%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:28<00:00, 36.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.70it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.71it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Loss: 0.4478, Train: 78.98%, Valid: 75.52% Test: 70.72%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.42it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.71it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.0330, Train: 79.14%, Valid: 78.39% Test: 74.37%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.37it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.54it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.7220, Train: 79.71%, Valid: 79.01% Test: 72.12%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.22it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.66it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.0209, Train: 80.24%, Valid: 75.61% Test: 72.67%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:26<00:00, 38.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.37it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.19it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.0288, Train: 80.82%, Valid: 79.42% Test: 72.76%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.13it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.83it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.0362, Train: 80.81%, Valid: 77.24% Test: 73.52%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.48it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.22it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.0154, Train: 81.63%, Valid: 78.56% Test: 73.58%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.56it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.34it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.0235, Train: 80.84%, Valid: 78.27% Test: 70.82%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.68it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.64it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.0279, Train: 82.24%, Valid: 81.06% Test: 74.20%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:26<00:00, 38.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.90it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.21it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.0499, Train: 82.29%, Valid: 77.43% Test: 74.74%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.75it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.05it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.0208, Train: 82.03%, Valid: 78.97% Test: 73.56%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 36.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.29it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.61it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.0400, Train: 81.94%, Valid: 76.07% Test: 73.44%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 36.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.81it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.12it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.0400, Train: 82.60%, Valid: 78.47% Test: 73.99%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.22it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.25it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.5770, Train: 83.08%, Valid: 77.91% Test: 75.50%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 36.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.35it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.08it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.0161, Train: 83.02%, Valid: 77.53% Test: 75.05%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.26it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.31it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.0246, Train: 83.81%, Valid: 76.04% Test: 72.85%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.81it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.35it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 0.7850, Train: 84.01%, Valid: 80.20% Test: 75.70%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.86it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.24it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.0235, Train: 83.63%, Valid: 76.44% Test: 75.30%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.83it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.90it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 57.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.0075, Train: 83.35%, Valid: 79.72% Test: 75.32%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:18<00:00, 56.22it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.88it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.0144, Train: 83.62%, Valid: 78.05% Test: 72.89%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:26<00:00, 38.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.53it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.96it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 56.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.0206, Train: 84.01%, Valid: 79.96% Test: 75.34%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:27<00:00, 37.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:17<00:00, 57.19it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.50it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:02<00:00, 58.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.0231, Train: 83.96%, Valid: 80.77% Test: 75.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    print('Training...')\n",
    "    loss = train(model, device, train_loader, optimizer, loss_fn)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    train_result = eval(model, device, train_loader, evaluator)\n",
    "    val_result = eval(model, device, valid_loader, evaluator)\n",
    "    test_result = eval(model, device, test_loader, evaluator)\n",
    "\n",
    "    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * valid_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Oq5QaG21dOOO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1029/1029 [00:15<00:00, 65.24it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:01<00:00, 69.86it/s]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:01<00:00, 69.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Train: 82.24%, Valid: 81.06% Test: 74.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
    "valid_acc = eval(best_model, device, valid_loader, evaluator)[dataset.eval_metric]\n",
    "test_acc = eval(best_model, device, test_loader, evaluator)[dataset.eval_metric]\n",
    "\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * train_acc:.2f}%, '\n",
    "      f'Valid: {100 * valid_acc:.2f}% '\n",
    "      f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uKs6j6t1ah3"
   },
   "source": [
    "## Question 6: What are your `best_model` validation and test ROC-AUC score? Please report them on Gradescope. For example, for an ROC-AUC score such as 50.01%, just report 50.01 and please don't include the percent sign. (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBi_t8n0iZ4P"
   },
   "source": [
    "## Question 7 (Optional): Experiment with other two global pooling layers other than mean pooling in Pytorch Geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taxEEWyh1_jq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7JXsMTBgeOI"
   },
   "source": [
    "# Submission\n",
    "\n",
    "In order to get credit, you must go submit your answers on Gradescope.\n",
    "\n",
    "Also, you need to submit the `ipynb` file of Colab 2, by clicking `File` and `Download .ipynb`. Please make sure that your output of each cell is available in your `ipynb` file."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "“CS224W - Colab 2.ipynb”的副本",
   "provenance": [
    {
     "file_id": "1Aa0eKSmyYef1gORvlHv7EeQzSVRb30eL",
     "timestamp": 1639900727884
    },
    {
     "file_id": "1Jc5CAEGZIvY0vka3mBdf0tqn2TaJr2O1",
     "timestamp": 1610408674518
    },
    {
     "file_id": "1gc6u6hItUKY9uJt6GXHaneSYCMaGcxp1",
     "timestamp": 1610395347938
    },
    {
     "file_id": "1CqWY4pk7_VFxi8K8v4asr18ed0Hs8FVA",
     "timestamp": 1578441204356
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
